\documentclass{itatnew}
%% !!!dolezite: ak pisete po slovensky alebo po cesky pouzite
%% \documentclass[slovensky]{itatnew}
%% \documentclass[cesky]{itatnew}

% Math shortcuts
\usepackage{amssymb}
\newcommand{\xx}{\mathrm{\mathbf{x}}}
\newcommand{\yy}{\mathrm{\mathbf{y}}}
\newcommand{\XX}{\mathrm{\mathbf{X}}}
\newcommand{\CC}{\mathrm{\mathbf{C}}}
\newcommand{\ttheta}{\mathbf{\theta}}
\newcommand{\eell}{\boldsymbol\ell}

\begin{document}

\title{Sampling Methods for Model Guided Sampling Optimization
  with Gaussian Processes}

\author{Lukáš Bajer\inst{1,2} \and Martin Holeňa\inst{2}}

\institute{Faculty of Mathematics and Physics, Charles University in Prague,\\
Malostranske nam. 25, 118 00 Prague 1, Czech Republic\\
\email{bajer@cs.cas.cz} \\
\and
Institute of Computer Science, Academy of Sciences of the Czech Republic,\\
Pod Vodarenskou vezi 2, 182 07 Prague 8, Czech Republic\\
\email{martin@cs.cas.cz}}

\maketitle              % typeset the title of the contribution

\begin{abstract}
Model Guided Sampling Optimization (MGSO) was recently proposed as an alternative for Jones' Kriging-based EGO algorithm for optimization of expensive black-box functions. Instead of maximizing a chosen criterion (e.g. expected improvement), MGSO samples probability of improvement forming multiple candidates -- a whole population of suggested solutions. This paper tackles problems with such sampling, it compares different sampling methods and suggests further development of the MGSO algorithm.
\end{abstract}

\section{Introduction}
%
Optimization of expensive empirical functions forms an important topic in many engineering or natural-sciences areas. For such functions, it is often impossible to obtain any derivatives or information about smoothness; moreover, there is no mathematical formula nor algorithm to evaluate. Instead, some simulation, or physical, chemical or computer experiment has to be performed, and measured value or result of such experiment is the value of the objective function being considered. These functions are also called black-box functions. Such empirical functions are usually very expensive to evaluate; one evaluation may cost a lot of time and money to process.

Because of the absence of the derivatives, standard continuous first- or second-order derivative optimization methods cannot be used. Further, this kind of functions are usually characterized by a high number of local optima in where simple algorithms can be trapped easily. Therefore, different derivative-free optimization methods for black-box functions (often called meta-heuristics) have been evolved. Even though these methods are slow and computational intensive, the cost of the evaluation of the empirical objective function is always much higher, and so the number of function evaluations is crucial to decrease as much as possible and the cost of these evaluations dominates the computational cost of the optimization algorithm.

Evolutionary algorithms \textbf{TODO-REF} constitute a broad family of meta-heuristics which are used for black-box optimization very frequently. Some kinds of these algorithms or some techniques are designed to spent for the optimization as few objective function evaluations as possible, all of the three following approaches use some kind of model being built and updated within the optimization process.

\emph{Estimation of distribution algorithms} (EDAs) \cite{larranaga_estimation_2002} represent one such approach: EDAs iteratively estimate probabilistic distribution of selected (usually better) candidate solutions and sample this distribution forming a new set of solution for the next iteration. 

\emph{Surrogate modelling} is a technique of construction and usage of a regression model of the objective function \textbf{TODO-REF}. The model (called surrogate model in this context) is then used to evaluate some of the candidate solutions instead of evaluating them with the original costly function.

Our method, \emph{Model Guided Sampling Optimization} (MGSO), is based on both these approaches. It is similar to Jones' Efficient Global Optimization (EGO)~\cite{jones_efficient_1998}: similar to EGO, MGSO uses Gaussian process (GP, see~\cite{rasmussen_gaussian_2006} for reference) which provides a guide where to sample new candidate solutions in order to explore new solutions and exploit promising areas of the objective-function landscape. EGO evaluates a solution where a chosen criterion, Expected Improvement (EI) or Probability of Improvement (PoI) is maximized. On the other hand, MGSO sample GP model's latter criterion -- PoI, producing a set of new points. Further, the GP serves as a surrogate model of the objective function for some of the solutions at the same time. During each iteration, MGSO samples the model's PoI forming a population of new candidate solutions, evaluates them and updates the GP model with the new gathered data.

This paper follows up to the previous brief introduction of MGSO~\cite{bajer_model_2013}. Instead of Gibbs' sampling, it uses slice sampling algorithm introduced by Neal~\cite{neal_slice_2003} which enables computational cheaper sampling in higher dimensions. Further, GP model is used as a surrogate model more often which brought faster convergence. The following section introduces methods used in the MGSO, third section further describes the MGSO algorithm and the fourth section bring some preliminary results from BBOB testing set~\cite{hansen_real_2009}.


\section{Involved methods}

\subsection{Gaussian processes}

Gaussian process~\cite{rasmussen_gaussian_2006} is a probabilistic model based on Gaussian distributions. It is specified by a set of data points, covariance and mean function and relatively small number of hyper-parameters. The hyper-parameters are set in such way that the likelihood of the function value given the values of the decision variables is maximized for the training data points.

The GP model can predict the function value in a new point in the form of univariate Gaussian distribution: the GP provides mean and standard deviation of the function value. Through the predicted mean, the GP can serve as a surrogate model, and standard deviation is a measure of uncertainty of the prediction in a specified point.

Let $\XX_N = \{\xx_i \ | \ \xx_i \in \mathbb{R}^{D}\}_{i=1}^{N}$ be a set of $N$ training data points with known dependent-variable values $\yy = \{y_i\}_{i=1}^{N}$ and $f(\xx)$ be an unknown function being modelled for which $f(\xx_i) = y_i$ for all $i \in \{1,\ldots,N\}$. The GP model imposes a probabilistic model on the data: the vector of known function values $\yy_N$ is considered as one sample of a $N$-dimensional multivariate Gaussian distribution with probability density $p(\yy \, | \, \XX_N)$. If we add a new data point ($\xx_{N+1}, y_{N+1})$, the probability density is, according to B\"{u}che \cite{buche_accelerating_2005},
\begin{equation}
p(\yy_{N+1} \, | \, \XX_{N+1}) = \frac { \exp(-\frac{1}{2} \yy^\top_{N+1} \CC^{-1}_{N+1} \yy_{N+1}) } { \sqrt{(2\pi)^{N+1} \det(\CC_{N+1})} }
\end{equation}
where $\CC_{N+1}$ is the covariance matrix of the Gaussian distribution (for which mean is usually set to constant zero). This covariance can be written as
\begin{equation}
\CC_{N+1} = \left( \begin{array}{cc} \CC_N & \mathbf{k} \\ \mathbf{k}^\top & \kappa \end{array} \right)
\end{equation}
where $\CC_N$ is the covariance of the Gaussian distribution given the $N$ training data points, $\mathbf{k}$ is a vector containing covariances between the new point and training data, and $\kappa$ is the variance of the new point itself. Further, inverse $\CC^{-1}_{N-1}$ of the extended covariance can be expressed using inverse of the training covariance $\CC^{-1}_N$ which simplifies density of the distribution in a new point to a univariate Gaussian with density
\begin{equation}
p(y_{N+1} \, | \, \XX_{N+1}, \yy_N) \ \varpropto \ \exp \left( -\frac{1}{2} \frac {(y_{N+1} - \hat{y}_{N+1})^2} {\sigma^2_{y_{N+1}}} \right)
\label{univariate-density}.
\end{equation}
with mean and variance given by
\begin{eqnarray}
\hat{y}_{N+1} & = & \mathbf{k}^\top \CC^{-1}_N \yy_N, \\
\sigma^2_{y_{N+1}} & = & \kappa - \mathbf{k}^\top \CC^{-1}_N \mathbf{k}.
\end{eqnarray}
Further details can be found in \cite{buche_accelerating_2005}.

The covariances $\CC_N$ plays a crucial role in these equations. Gaussian processes use parametrized covariance functions $C$ describing prior assumptions on the shape of the modeled function. The covariance between the function values at two data points $\xx_p$ and $\xx_q$ is given by $C(\xx_p, \xx_q)$ which forms also the $(p,q)$-th element of the matrix $\CC_N$. In our case, we used the most common squared-exponential function
\begin{equation}
C(\xx_p, \xx_q) = \theta_1 \exp \left( -\frac{1}{2} \sum^D_{i=1} \frac{(x^i_p - x^i_q)^2} {2l^2} \right) + \theta_2 + \delta_{p,q}\theta_3
\end{equation}
which is suitable when the modelled function is rather smooth. The closer the points $\xx_p$ and $\xx_q$ are, the closer the covariance function value is to 1 and the stronger correlation between function values $f(\xx_p)$ and $f(\xx_q)$ is. The hyper-parameter $\theta_1$ scales this correlation, $\theta_2$ rises the value from zero and $\theta_3$ means a white noise of the diagonal elements of the matrix. The last parameter $l$ is the length-scale with which the distance of two considered data points is compared. Estimate of these hyper-parameters can be supplied by the user and the final value is usually learnt using maximum-likelihood approach.


\subsection{Sampling}

The core of the MGSO algorithm is made by sampling of the probability of improvement. This measure is for a chosen threshold $T$ of the function value directly given by predicted $\hat{y}_{N+1}$ mean and standard deviation $\sigma_{y_{N+1}}$ of the GP model in any point of the input space
\begin{equation}
  \mathrm{PoI}_T(\xx) = \mathrm{\Phi}\left( \frac{T - \hat{y}_{N+1}}{\sigma_{y_{N+1}}} \right).
\end{equation}
which corresponds to the value of cumulative distribution function (CDF) of the Gaussian with density (\ref{univariate-density}) for value $T$. Even though all the variables comes from Gaussian distribution, $\mathrm{PoI}(\xx)$ is definitely not Gaussian-shaped and depends on the threshold and modelled function -- typical example of the landscape of $\textrm{PoI}(\xx)$ in two dimensions for Rastrigin function is depicted in Fig.\,\textbf{TODO-FIG}. The dependency on the modelled function causes also no analytical marginals, derivatives or conditional probabilities.

The first version of MGSO~\cite{bajer_model_2013} used Gibb's sampler~\cite{geman_stochastic_1984}. 


% \noindent ==================
% 
% Evolutionary algorithms evolve in parallel a set of candidate solutions (a population) in multiple steps. Every iteration (in evolutionary context called generation) the candidate solutions (individuals) are evaluated with the objective function (so called fitness function). Then, some of these individuals are selected; the better ones are preferred. Finally, the selected individuals are modified or recombined between each other, a new population is created and a new generation starts again.
% 
% \paragraph{Surrogate Modelling.}
% Approximation of the fitness function with some regression model is a common cure for tasks when empirical objective function has to be used. These \textit{surrogate models} simulate behaviour of the original function while being much cheaper and much less time consuming to evaluate. As a surrogate model, any suitable regression model can be used~\cite{hosder2001polynomial,buche2005accelerating,ulmer2005model}.
% 
% In connection with evolutionary optimization, artificial neural networks of the type multilayer perceptrons \cite{jin2005neural} and networks with radial basis functions \cite{zhou2007combining,ong2004surrogate} have been particularly popular. The last mentioned kind of neural networks underlies also the model reported in this paper.





\subsection*{Acknowledgments}

This work was supported by the Czech Science Foundation (GA\v{C}R) grants \hbox{P202/11/1368} and \hbox{13-17187S}, and the Grant Agency of the Charles University (GAUK) \hbox{278511/2011} grant. 

%
% ---- Bibliography ----
%
\bibliography{bajer2013itat}  % sigproc.bib is the name of the Bibliography in this case
\bibliographystyle{abbrv}

% %
% \begin{thebibliography}{5}
% %
% \bibitem {clar:eke}
% Clarke, F., Ekeland, I.:
% Nonlinear oscillations and
% boundary-value problems for Hamiltonian systems.
% Arch. Rat. Mech. Anal. {\bf 78} (1982) 315--333
% 
% \bibitem {clar:eke:2}
% Clarke, F., Ekeland, I.:
% Solutions p\'{e}riodiques, du
% p\'{e}riode donn\'{e}e, des \'{e}quations hamiltoniennes.
% Note CRAS Paris {\bf 287} (1978) 1013--1015
% 
% \bibitem {mich:tar}
% Michalek, R., Tarantello, G.:
% Subharmonic solutions with prescribed minimal
% period for nonautonomous Hamiltonian systems.
% J. Diff. Eq. {\bf 72} (1988) 28--55
% 
% \bibitem {tar}
% Tarantello, G.:
% Subharmonic solutions for Hamiltonian
% systems via a $\bbbz_{p}$ pseudoindex theory.
% Annali di Matematica Pura (to appear)
% 
% \bibitem {rab}
% Rabinowitz, P.:
% On subharmonic solutions of a Hamiltonian system.
% Comm. Pure Appl. Math. {\bf 33} (1980) 609--633
% 
% \end{thebibliography}

\end{document}
